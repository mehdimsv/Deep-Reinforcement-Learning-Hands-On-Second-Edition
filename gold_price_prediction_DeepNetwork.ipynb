{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gold_price_prediction_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdimsv/Deep-Reinforcement-Learning-Hands-On-Second-Edition/blob/master/gold_price_prediction_DeepNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htxyszJKqWhD",
        "outputId": "b4ac365b-5fc4-4ac2-d963-360c015ab66d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 29 13:46:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4coFPpUZoOLZ"
      },
      "source": [
        "try:\n",
        "  from tqdm import tqdm\n",
        "except :\n",
        "  !pip install --quiet tqdm==4.59.0\n",
        "  from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdh2l2Sxq5mL"
      },
      "source": [
        "dir_path=\"gdrive/My Drive/ML4T/gold_prediction\"\n",
        "file_name=\"XAUUSD15_final.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFfgDkIj2q7m",
        "outputId": "7d2822cb-946b-4033-b8fc-e9809e21b064"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtGeiuox2lJY",
        "outputId": "e97a9389-5db4-4316-c128-8f84ccc98f2f"
      },
      "source": [
        "print(os.getcwd())\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5jC5jAuovz1",
        "outputId": "1bdc2978-f5ae-4d84-9191-f081233f1136"
      },
      "source": [
        "!cd gdrive\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAxoESvQoWyk"
      },
      "source": [
        "if not os.getcwd().endswith(\"gold_prediction\"):\n",
        "  os.chdir(dir_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgEKn3xfq_7h"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d8U6DRxKZfq"
      },
      "source": [
        "df=pd.read_csv(file_name)\n",
        "#df.set_index(\"date\",inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MvcgGTxFLA-E",
        "outputId": "acfa920d-d109-49f1-f472-182386ae66b6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>day_of_month_1</th>\n",
              "      <th>day_of_month_2</th>\n",
              "      <th>day_of_month_3</th>\n",
              "      <th>day_of_month_4</th>\n",
              "      <th>day_of_month_5</th>\n",
              "      <th>day_of_month_6</th>\n",
              "      <th>day_of_month_7</th>\n",
              "      <th>day_of_month_8</th>\n",
              "      <th>day_of_month_9</th>\n",
              "      <th>day_of_month_10</th>\n",
              "      <th>day_of_month_11</th>\n",
              "      <th>day_of_month_12</th>\n",
              "      <th>day_of_month_13</th>\n",
              "      <th>day_of_month_14</th>\n",
              "      <th>day_of_month_15</th>\n",
              "      <th>day_of_month_16</th>\n",
              "      <th>day_of_month_17</th>\n",
              "      <th>day_of_month_18</th>\n",
              "      <th>day_of_month_19</th>\n",
              "      <th>day_of_month_20</th>\n",
              "      <th>day_of_month_21</th>\n",
              "      <th>day_of_month_22</th>\n",
              "      <th>day_of_month_23</th>\n",
              "      <th>day_of_month_24</th>\n",
              "      <th>day_of_month_25</th>\n",
              "      <th>day_of_month_26</th>\n",
              "      <th>day_of_month_27</th>\n",
              "      <th>day_of_month_28</th>\n",
              "      <th>day_of_month_29</th>\n",
              "      <th>day_of_month_30</th>\n",
              "      <th>day_of_month_31</th>\n",
              "      <th>day_0</th>\n",
              "      <th>day_1</th>\n",
              "      <th>day_2</th>\n",
              "      <th>day_3</th>\n",
              "      <th>day_4</th>\n",
              "      <th>day_6</th>\n",
              "      <th>hour_0</th>\n",
              "      <th>hour_1</th>\n",
              "      <th>...</th>\n",
              "      <th>percent_avg_candle_size_9</th>\n",
              "      <th>percent_avg_candle_size_20</th>\n",
              "      <th>candle_schema_0</th>\n",
              "      <th>candle_schema_1</th>\n",
              "      <th>candle_schema_2</th>\n",
              "      <th>candle_schema_3</th>\n",
              "      <th>candle_schema_4</th>\n",
              "      <th>candle_schema_5</th>\n",
              "      <th>candle_schema_6</th>\n",
              "      <th>candle_schema_7</th>\n",
              "      <th>candle_schema_8</th>\n",
              "      <th>candle_schema_9</th>\n",
              "      <th>sma5_-1</th>\n",
              "      <th>sma5_1</th>\n",
              "      <th>sma14_-1</th>\n",
              "      <th>sma14_1</th>\n",
              "      <th>sma21_-1</th>\n",
              "      <th>sma21_1</th>\n",
              "      <th>ema5_-1</th>\n",
              "      <th>ema5_1</th>\n",
              "      <th>ema14_-1</th>\n",
              "      <th>ema14_1</th>\n",
              "      <th>ema200_-1</th>\n",
              "      <th>ema200_1</th>\n",
              "      <th>mid_-1</th>\n",
              "      <th>mid_1</th>\n",
              "      <th>upper_band_-1</th>\n",
              "      <th>upper_band_1</th>\n",
              "      <th>lower_band_-1</th>\n",
              "      <th>lower_band_1</th>\n",
              "      <th>candle_type_-1</th>\n",
              "      <th>candle_type_0</th>\n",
              "      <th>candle_type_1</th>\n",
              "      <th>intersect_with_previous_candle</th>\n",
              "      <th>current_label_-1</th>\n",
              "      <th>current_label_0</th>\n",
              "      <th>current_label_1</th>\n",
              "      <th>label_-1</th>\n",
              "      <th>label_0</th>\n",
              "      <th>label_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-10-25 00:30:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-10-25 00:45:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-10-25 01:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-10-25 01:15:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-10-25 01:30:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 114 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date  day_of_month_1  ...  label_0  label_1\n",
              "0  2012-10-25 00:30:00               0  ...        1        0\n",
              "1  2012-10-25 00:45:00               0  ...        1        0\n",
              "2  2012-10-25 01:00:00               0  ...        1        0\n",
              "3  2012-10-25 01:15:00               0  ...        1        0\n",
              "4  2012-10-25 01:30:00               0  ...        1        0\n",
              "\n",
              "[5 rows x 114 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMOgTMglfY-r"
      },
      "source": [
        "##Convert label categories to one column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCsg6TbDfYZb"
      },
      "source": [
        "cols=list(df.columns.values[1:])\n",
        "data_df=df.loc[:,cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ3b0yCagx6Q",
        "outputId": "bba6eb93-e1bc-4cbe-d90d-3aa45c09f91c"
      },
      "source": [
        "print(data_df.columns.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['day_of_month_1' 'day_of_month_2' 'day_of_month_3' 'day_of_month_4'\n",
            " 'day_of_month_5' 'day_of_month_6' 'day_of_month_7' 'day_of_month_8'\n",
            " 'day_of_month_9' 'day_of_month_10' 'day_of_month_11' 'day_of_month_12'\n",
            " 'day_of_month_13' 'day_of_month_14' 'day_of_month_15' 'day_of_month_16'\n",
            " 'day_of_month_17' 'day_of_month_18' 'day_of_month_19' 'day_of_month_20'\n",
            " 'day_of_month_21' 'day_of_month_22' 'day_of_month_23' 'day_of_month_24'\n",
            " 'day_of_month_25' 'day_of_month_26' 'day_of_month_27' 'day_of_month_28'\n",
            " 'day_of_month_29' 'day_of_month_30' 'day_of_month_31' 'day_0' 'day_1'\n",
            " 'day_2' 'day_3' 'day_4' 'day_6' 'hour_0' 'hour_1' 'hour_2' 'hour_3'\n",
            " 'hour_4' 'hour_5' 'hour_6' 'hour_7' 'hour_8' 'hour_9' 'hour_10' 'hour_11'\n",
            " 'hour_12' 'hour_13' 'hour_14' 'hour_15' 'hour_16' 'hour_17' 'hour_18'\n",
            " 'hour_19' 'hour_20' 'hour_21' 'hour_22' 'hour_23' 'min30' 'momentum5'\n",
            " 'momentum14' 'macd' 'macdsignal' 'macdhist' 'bbp' 'atr5' 'atr14' 'adx5'\n",
            " 'adx14' 'percent_of_body' 'percent_avg_candle_size_9'\n",
            " 'percent_avg_candle_size_20' 'candle_schema_0' 'candle_schema_1'\n",
            " 'candle_schema_2' 'candle_schema_3' 'candle_schema_4' 'candle_schema_5'\n",
            " 'candle_schema_6' 'candle_schema_7' 'candle_schema_8' 'candle_schema_9'\n",
            " 'sma5_-1' 'sma5_1' 'sma14_-1' 'sma14_1' 'sma21_-1' 'sma21_1' 'ema5_-1'\n",
            " 'ema5_1' 'ema14_-1' 'ema14_1' 'ema200_-1' 'ema200_1' 'mid_-1' 'mid_1'\n",
            " 'upper_band_-1' 'upper_band_1' 'lower_band_-1' 'lower_band_1'\n",
            " 'candle_type_-1' 'candle_type_0' 'candle_type_1'\n",
            " 'intersect_with_previous_candle' 'current_label_-1' 'current_label_0'\n",
            " 'current_label_1' 'label_-1' 'label_0' 'label_1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtaRSqMefdyh"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx8G14z3rO86"
      },
      "source": [
        "NUM_CLASSES=3\n",
        "percent=0.85\n",
        "train_size=int(data_df.shape[0]*percent)\n",
        "x_train=data_df[:train_size]\n",
        "x_test=data_df[train_size+1:]\n",
        "x_train=x_train.dropna()\n",
        "#x_train=normalize_data(x_train)\n",
        "x_test=x_test.dropna()\n",
        "#x_test=normalize_data(x_test)\n",
        "x_test=x_test.reset_index()\n",
        "\n",
        "x_train=x_train.values\n",
        "x_test=x_test.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9jp21ifrQwF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hipxZTqCrilQ"
      },
      "source": [
        "class FeatureDataset(Dataset):\n",
        "  def __init__(self,data):\n",
        "    self.data=data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    features=self.data[idx,:-3]\n",
        "    labels=self.data[idx,-3:]\n",
        "    return torch.Tensor(features),torch.from_numpy(labels).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CklfXTYcrklv"
      },
      "source": [
        "N_EPOCHS=250\n",
        "BATCH_SIZE=64\n",
        "train_dataloader=DataLoader(\n",
        "    FeatureDataset(x_train),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True\n",
        "\n",
        ")\n",
        "test_dataloader=DataLoader(\n",
        "    FeatureDataset(x_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    drop_last=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2rvT8McTQxw"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIEh1pKNNBdD",
        "outputId": "06631ef0-b5b6-4e8e-ef68-4b4e84ef2dfe"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXbLUf84ODrm"
      },
      "source": [
        "class DeepModel(nn.Module):\n",
        "  def __init__(self,batch_size,n_features,n_classes=3,dropout=0.7):\n",
        "    super(DeepModel,self).__init__()\n",
        "    self.n_classes=n_classes\n",
        "    self.fc1=nn.Linear(n_features,1024)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.fc2=nn.Linear(n_features,512)\n",
        "    self.dropout2=nn.Dropout(dropout)\n",
        "    self.classifier=nn.Linear(512,n_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    print(\"x shape:\",x.shape)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    #x=self.dropout(x)\n",
        "    x=F.relu(self.fc2(x))\n",
        "    #x=self.dropout(x)\n",
        "    print(\"x shape:\",x.shape)\n",
        "    x= self.classifier(x)\n",
        "    print(\"result :\",x.shape)\n",
        "    return F.log_softmax(x,dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9JnJ5gwTUQi"
      },
      "source": [
        "## Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rdRuCTXrpG8"
      },
      "source": [
        "#model=PricePredictionModel(BATCH_SIZE,data_df.shape[1])\n",
        "model=DeepModel(BATCH_SIZE,data_df.shape[1]-3)\n",
        "model=model.to(device)\n",
        "#odel.hidden_state=model.init_hidden(BATCH_SIZE)\n",
        "weights = torch.tensor([1.5,0.1,1.5]).to(device)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BS6bjZEiAsn",
        "outputId": "1b7e6a43-7906-4635-c37f-92ba1548569e"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepModel(\n",
            "  (fc1): Linear(in_features=110, out_features=1024, bias=True)\n",
            "  (dropout): Dropout(p=0.7, inplace=False)\n",
            "  (fc2): Linear(in_features=110, out_features=512, bias=True)\n",
            "  (dropout2): Dropout(p=0.7, inplace=False)\n",
            "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3g5cHbkTYDQ"
      },
      "source": [
        "## Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyDAQBnIq_IR"
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    _,pred = torch.max(out, dim=1)\n",
        "    return torch.sum(pred==labels).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8rXsfx4rq8a"
      },
      "source": [
        "def train(dataloader,model,loss_fn,optimizer,epoch):\n",
        "  #size=len(dataloader.dataset)\n",
        "  #torch.autograd.set_detect_anomaly(True)\n",
        "  #hidden = model.init_hidden(BATCH_SIZE)\n",
        "  model.train()\n",
        "  running_loss=0.0\n",
        "  running_correct=0.0\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    if batch==2:\n",
        "      break\n",
        "    X=X.to(device)\n",
        "    y=y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    #compute prediction Error\n",
        "    #hidden=(hidden[0].detach(),hidden[1].detach())\n",
        "    pred=model(X)\n",
        "    print(\"pred shape :\",pred.shape)\n",
        "    print(\"--------\")\n",
        "    print(\"y shape:\",y.shape)\n",
        "    pred = torch.squeeze(pred)\n",
        "    print(\"pred shape:\",pred.shape)\n",
        "    loss=loss_fn(pred,y)\n",
        "    step_accuracy=accuracy(torch.argmax(y.detach().to(\"cpu\"),dim=1),torch.argmax(pred.detach().to(\"cpu\"),dim=1))\n",
        "\n",
        "    #Backpropagation\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "    running_correct+=(torch.argmax(pred.detach(),dim=1)==torch.argmax(y,dim=1)).type(torch.float).sum().item()\n",
        "    if batch % 100==0:\n",
        "      loss,current=loss.item(),batch*len(X)\n",
        "      print(f\"loss: {loss:>7f}   [{current:>5d}/{size:>5d}], accuracy:{step_accuracy*100}%\")\n",
        "  running_loss/=size\n",
        "  running_correct/=size\n",
        "  writer.add_scalar(\"Loss/train\",running_loss , epoch)\n",
        "  writer.add_scalar(\"Accuracy/train\",running_correct, epoch)\n",
        "  print(f\"Average Loss: {running_loss:>7f}   ,Avg accuracy:{running_correct*100}%\")\n",
        "  writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7x3XoRKrtCz"
      },
      "source": [
        "def test(dataloader,model,epoch):\n",
        "  size=len(dataloader.dataset)\n",
        "  model.eval()\n",
        "  test_loss,correct=0,0\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      X=X.to(device)\n",
        "      y=y.to(device)\n",
        "      pred=model(X)\n",
        "     \n",
        "      test_loss+=loss_fn(pred,y).item()\n",
        "      #step_accuracy=accuracy_score(y.detach().to(\"cpu\"),torch.argmax(pred.detach().to(\"cpu\"),dim=1))\n",
        "      correct+=(torch.argmax(pred.detach(),dim=1)==y).type(torch.float).sum().item()\n",
        "\n",
        "  \n",
        "  test_loss/=size\n",
        "  correct/=size\n",
        "  writer.add_scalar(\"Loss/test\", test_loss,epoch)\n",
        "  writer.add_scalar(\"Accuracy/test\", correct,epoch)\n",
        "  print(f\"Test Error: \\n Accuracy:{(100*correct):>0.1f}%, Avg loss:{test_loss:>8f}\\n\")\n",
        "  writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okpNDzyMTbfp"
      },
      "source": [
        "## Loading TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEXhgb_iTgNJ"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "nj1oxsV6rvYX",
        "outputId": "82c21e6b-1d26-401c-d56e-5c165ef6648c"
      },
      "source": [
        "epochs=250\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch+1} \\n---------------------------------------\")\n",
        "  train(train_dataloader,model,loss_fn,optimizer,epoch)\n",
        "  test(test_dataloader,model,epoch)\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss_fn\n",
        "            }, \"gold-price-prediction-model-resume.pth\")\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "---------------------------------------\n",
            "x shape: torch.Size([64, 110])\n",
            "x shape: torch.Size([64, 512])\n",
            "result : torch.Size([64, 3])\n",
            "pred shape : torch.Size([64, 3])\n",
            "--------\n",
            "y shape: torch.Size([64, 3])\n",
            "pred shape: torch.Size([64, 3])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c170b608b8f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1} \\n---------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   torch.save({\n",
            "\u001b[0;32m<ipython-input-41-292af5554a06>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred shape:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mstep_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1121\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AomaM3dPryCJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}